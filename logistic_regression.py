# -*- coding: utf-8 -*-
"""logistic regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a3ucezDCqs1T5_GVjyQIj0pesAx3it-u
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report,confusion_matrix
import seaborn as sns

a=pd.read_csv("/content/diabetes.csv")
a.head()

a.tail()

a.describe

a.isnull().sum()

b=a.corr()

sns.heatmap(b,annot=True)
plt.show

x = a.drop('diabetes',axis=1)
y = a['diabetes']

x=a.iloc[:,:2]
y=a.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)

c = LogisticRegression(C=0.5)
c.fit(x,y)

c.classes_

c.intercept_

c.coef_

c.predict_proba(x)

y_pred = c.predict(x)
print(y_pred)

c.score(x, y)

confusion_matrix(y, y_pred)

cm = confusion_matrix(y, y_pred)

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm)
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')
plt.show()